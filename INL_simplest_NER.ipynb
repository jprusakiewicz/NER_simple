{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"NKJP_org.csv\") as f:\n",
    "    text= f.read()\n",
    "sentences = text.split(\"\\n\\n\")\n",
    "split_sentences = [sentence.split(\"\\n\") for sentence in sentences if any(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sentences = []\n",
    "for sentence in split_sentences:\n",
    "    s = []\n",
    "    for word in sentence:\n",
    "        s.append(word.split(\"\\t\"))\n",
    "    grouped_sentences.append(s)\n",
    "    \n",
    "for sentence in grouped_sentences:\n",
    "    for word in sentence:\n",
    "        if len(word) == 2:\n",
    "            word.extend([\"O\", \"O\"])\n",
    "        if len(word) == 3:\n",
    "            word.insert(2, 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.hist([len(sen) for sen in grouped_sentences], bins= 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biggest_len = max([len(s) for s in grouped_sentences])\n",
    "biggest_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "all_labels = []\n",
    "all_tokens = ['<PAD>']\n",
    "for sentences in grouped_sentences:\n",
    "    if len(sentences) <= max_len:\n",
    "        tokens = [sentence[0] for sentence in sentences]\n",
    "        labels = [sentence[3] for sentence in sentences]\n",
    "        assert len(tokens) <= max_len\n",
    "        pads_number_to_extend = max_len-len(tokens)\n",
    "        tokens.extend(['<PAD>'] * pads_number_to_extend)\n",
    "        labels.extend(['O'] * pads_number_to_extend)\n",
    "        assert len(tokens) == max_len\n",
    "        assert len(labels) == max_len\n",
    "        data.append({'tokens': tokens, \"labels\": labels})\n",
    "        all_tokens.extend(tokens)\n",
    "        all_labels.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140583, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_number = len(set(all_tokens))\n",
    "labels_number = len(set(all_labels))\n",
    "tokens_number, labels_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O',\n",
       " 'addName',\n",
       " 'bloc',\n",
       " 'country',\n",
       " 'date',\n",
       " 'district',\n",
       " 'forename',\n",
       " 'geogName',\n",
       " 'orgName',\n",
       " 'persName',\n",
       " 'placeName',\n",
       " 'region',\n",
       " 'settlement',\n",
       " 'surname',\n",
       " 'time'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2index = {w:i for i,w in enumerate(list(set(all_tokens)))}\n",
    "tags2index = {t:i for i,t in enumerate(list(set(all_labels)))}\n",
    "index2words = {i:w for i,w in enumerate(list(set(all_tokens)))}\n",
    "index2tags = {i:t for i,t in enumerate(list(set(all_labels)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3007\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(words2index['Liceum'])\n",
    "print(tags2index['geogName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['Bohaterem',\n",
       "  'powieści',\n",
       "  'Paźniewskiego',\n",
       "  'jest',\n",
       "  'miasto',\n",
       "  ',',\n",
       "  'Krzemieniec',\n",
       "  '.',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>'],\n",
       " 'labels': ['O',\n",
       "  'O',\n",
       "  'surname',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'settlement',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[words2index[w] for w in sentence['tokens']] for sentence in data]\n",
    "y = [[tags2index[w] for w in sentence['labels']] for sentence in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_hub in /home/kuba/.local/lib/python3.8/site-packages (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/kuba/.local/lib/python3.8/site-packages (from tensorflow_hub) (1.22.4)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/kuba/.local/lib/python3.8/site-packages (from tensorflow_hub) (3.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kuba/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Input, add\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val = np.array(X_tr[:1213*batch_size]), np.array(X_tr[-135*batch_size:])\n",
    "y_tr, y_val = np.array(y_tr[:1213*batch_size]), np.array(np.array(y_tr[-135*batch_size:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te = np.array(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)\n",
    "y_val = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_te = np.array(y_te)\n",
    "y_te = y_te.reshape(y_te.shape[0], y_te.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68172, 55)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X_tr) == len(y_tr)\n",
    "assert len(X_val) == len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kuba/.local/lib/python3.8/site-packages/keras/initializers/initializers_v1.py:277: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:From /home/kuba/.local/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/kuba/.local/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/kuba/.local/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "input_text = Input(shape=(55,))\n",
    "embedding = Embedding(\n",
    "        input_dim=tokens_number+1,\n",
    "        input_length=max_len,\n",
    "        output_dim=20,\n",
    "        mask_zero=True\n",
    "       )(input_text)\n",
    "x = Bidirectional(LSTM(units=512, return_sequences=True,\n",
    "                       recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
    "x_rnn = Bidirectional(LSTM(units=512, return_sequences=True,\n",
    "                           recurrent_dropout=0.2, dropout=0.2))(x)\n",
    "_x = add([x, x_rnn])\n",
    "out = TimeDistributed(Dense(labels_number, activation=\"softmax\"))(_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_text, out)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68172 samples, validate on 34560 samples\n",
      "Epoch 1/3\n",
      "68172/68172 [==============================] - ETA: 0s - loss: 0.2405 - acc: 0.9826"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68172/68172 [==============================] - 402s 6ms/sample - loss: 0.2405 - acc: 0.9826 - val_loss: 0.2258 - val_acc: 0.9860\n",
      "Epoch 2/3\n",
      "68172/68172 [==============================] - 396s 6ms/sample - loss: 0.2249 - acc: 0.9860 - val_loss: 0.2258 - val_acc: 0.9860\n",
      "Epoch 3/3\n",
      "68172/68172 [==============================] - 396s 6ms/sample - loss: 0.2249 - acc: 0.9860 - val_loss: 0.2258 - val_acc: 0.9860\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, y_tr, validation_data=(X_val, y_val),\n",
    "                    batch_size=batch_size, epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "X_te = X_te[:149*batch_size]\n",
    "test_pred = model.predict(np.array(X_te), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.22584213756314678\n",
      "Test accuracy: 98.6%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_te, y_te, batch_size=256)\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kuba/.local/lib/python3.8/site-packages/keras/initializers/initializers_v1.py:277: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:From /home/kuba/.local/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/kuba/.local/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/kuba/.local/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "input_text_2 = Input(shape=(55,))\n",
    "embedding_2 = Embedding(\n",
    "        input_dim=tokens_number+1,\n",
    "        input_length=max_len,\n",
    "        output_dim=20,\n",
    "        mask_zero=True\n",
    "       )(input_text_2)\n",
    "x_1 = Bidirectional(LSTM(units=256, return_sequences=True,\n",
    "                       recurrent_dropout=0.4, dropout=0.4))(embedding_2)\n",
    "x_rnn_1 = Bidirectional(LSTM(units=256, return_sequences=True,\n",
    "                           recurrent_dropout=0.4, dropout=0.4))(x_1)\n",
    "_x_1 = add([x_1, x_rnn_1])\n",
    "x_2 = Bidirectional(LSTM(units=512, return_sequences=True,\n",
    "                       recurrent_dropout=0.2, dropout=0.2))(_x_1)\n",
    "x_rnn_2 = Bidirectional(LSTM(units=512, return_sequences=True,\n",
    "                           recurrent_dropout=0.2, dropout=0.2))(x_2)\n",
    "_x_2 = add([x_2, x_rnn_2])\n",
    "\n",
    "out_2 = TimeDistributed(Dense(labels_number, activation=\"softmax\"))(_x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Model(input_text_2, out_2)\n",
    "model_2.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68172 samples, validate on 8640 samples\n",
      "Epoch 1/3\n",
      "68172/68172 [==============================] - ETA: 0s - loss: 0.2277 - acc: 0.9852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68172/68172 [==============================] - 1572s 23ms/sample - loss: 0.2277 - acc: 0.9852 - val_loss: 0.2265 - val_acc: 0.9859\n",
      "Epoch 2/3\n",
      "68172/68172 [==============================] - 1564s 23ms/sample - loss: 0.2249 - acc: 0.9860 - val_loss: 0.2265 - val_acc: 0.9859\n",
      "Epoch 3/3\n",
      "68172/68172 [==============================] - 1580s 23ms/sample - loss: 0.2249 - acc: 0.9860 - val_loss: 0.2265 - val_acc: 0.9859\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(X_tr, y_tr, validation_data=(X_val, y_val),\n",
    "                    batch_size=batch_size, epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.22584216072058122\n",
      "Test accuracy: 98.6%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_2.evaluate(X_te, y_te, batch_size=64)\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_2.predict(X_te, batch_size=64, verbose=1)\n",
    "y_true_bool = np.argmax(y_te, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.933756"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_m(y_te, y_pred.astype('float64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do wytrenowania modelu NER wykorzystano dane z kanału teams. Składało się na nie 140583 słów i 15 etykiet. Przed podaniem ich do modelu w pierwszej kolejności zamieniono słowa na wartości numeryczne, używając najprostszej metody- worka słów. potem wyrównano wszystkie zdania do równej długości wstawiając w te któtsze frazę '<PAD>' i odpowiadającą jej pustą etykietę 'O'. Architektura modelu sieci neuronowej oparta jest na warstwach dwukierunkowych LSTM- które uczą się, co przechowywać w staniedługoterminowym, co wyrzucić i co z niego czytać. By zapobiec przetrenowaniu się sieci zastosowano parametr dropout, który losowo usuwał 20% połączeń podczas treningu. Poskutkowało to zadowalającym wynikiem powyżej 98,5% accuracy zarówno na zbiorze walidacyjnym jak i testowym. Dodanie większej ilości warstw LSTM nie poprawiło rezultatu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
